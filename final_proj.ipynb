{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import json\n",
    "from datetime import timedelta, date, datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd() + '/mfp-diaries.tsv'\n",
    "data = pd.read_csv(path, sep='\\t')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " მონაცემების საკმაოდ მოცულობითია 587186 სტრიქონი 4 სვეტზე. თითოეული სტიქონისთვის გვაქს აიდი, რომელიც იუზერის მაინდიფიცირებელი რიცხვია(1) , გვაქვს თარიღი(2), რომელ დღესაც იუზერმა შეიყვანა აპლიკაციაში მონაცემები. გვაქვს თვითონ მონაცემები , რომელიც იუზერმა შეიყვანა (3) . ეს მონაცემები დიქშენერების მასივი , რომელშიცი ისევ დიქშენერებია. თითოეულ ელემენტს აქვს საჭმლის სახელი, შემცველი ნუტრიენტები(ცილები , ცხიმები , ნახშირწყლები ... ).მეოთხე სვეტში არის ტოტალური რაოდენობა ნუტრიენტების და მიზანი . ანუ რა მიზანი ჰქონდა დასახული აპლიკაციას და რა რაოდენობის ნუტრიენტები მოიხმარა მომხმარებელმა . ერთი შეხედვით მონაცემები ისეთი სახითაა წარმოდგენილი , რომ სავარაუდოდ ანომალიათა და დივერგენციების რაოდენობა საკმაოდ იქნება . \n",
    "### დავიწყოთ ამ მონაცემების დაპარსვა,  და მათი გასუფთავება  ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "შევხედოთ დროის რა მონაკვეთში არის მონაცემები ასახული ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"First Date: \", data[data.columns[1]].unique().min())\n",
    "print(\"Last Date: \",data[data.columns[1]].unique().max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "შევხედოთ რამდენი განსხვავებული თარიღი გვხვდება"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniques = data[data.columns[1]].unique()\n",
    "print(\"unique dates: \", len(uniques))\n",
    "start = datetime.strptime('2014-09-14','%Y-%m-%d').date()\n",
    "end = datetime.strptime('2015-04-09','%Y-%m-%d').date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ვხედავთ თარიღების დუპლიკაცია არაა რადგან 2015-04-09 - 2014-09-14 = 208 დღეს\n",
    "ვნახოთ როგორი სიხშირით იყენებდა ხალხი აპლიკაციას. ეს საშუალებას მოგვცემს განვსაზღვროთ როგორი დინამიკა იყო ამ დროის პერიოდის განმავლობაში."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_activity = np.zeros(data[data.columns[0]].unique().max())\n",
    "for i in range( int((end-start).days)+1):\n",
    "    dat = start+timedelta(i)\n",
    "    dat_str = dat.strftime('%Y-%m-%d')\n",
    "    curr_dt = data[data[data.columns[1]]==dat_str]\n",
    "    for j in range(curr_dt.shape[0]):\n",
    "        user_activity[curr_dt.iloc[j,0]-1]+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(user_activity, bins=50)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of User Activity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ვხედავთ იუზერების აქტივობა დროის პერიოდის დასაწყისში ბევრად უფრო მეტი იყო და დროთა განმავლობაში დაიკლო ხოლო ბოლოს ისევ მოიმტა. სავარაუდოდ მსგავსი დინამიკა დამოკიდბულია აპლიკაციის გამოსვლის და მისი აქტუალურობის ასპქტთან . ამასთანავე დროის პერიოდი როდესაც ყველაზე მაღალია აქტივობა არის შემოდგომის პერიოდი. ეს მონაცემიც შეგვიძლია გამოვიყენოთ იმის გასაგებად , თუ რა დროს არის ყველაზე მეტი სარგებლის მომტანი აპლიკაციის გაპიარება . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც ვნახეთ ზევით , თითოეული საჭმელი შეიცავს გარკვეულ ნუტრიენტებს . ჩვენთვის საინტერესო გახდა რა \n",
    "ნუტრინენტებია მონაცემებში და რა რაოდენობით . სავარაუდოდ ზოგიერთი ნუტრიენტი ნაკლებად იქნება , ზოგიერთი მეტი,\n",
    "რაც  მსგავსი ნუტრიენტების გადაგდების საშუალებას მოგვცემს"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "თითოეულ საჭმელს აქვს dishes პარამეტრი და თითოეულ dish_ში არის ნუტრიენტების მასივი . თითოეულ ნუტრიენტს აქვს სახელი და მისი შესაბამისი რაოდენობა . პრიველ ჯერზე დავთვალოთ რამდენჯერ გვხვდება თითოეული ნუტრიენტი მონაცემებში."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_nutritions = {}\n",
    "for i in range(data.shape[0]):\n",
    "    foods = json.loads(data.iloc[i,2])\n",
    "    for j in range(len(foods)):\n",
    "        dishes = foods[j]['dishes']\n",
    "        \n",
    "        for curr_dish in range(len(dishes)):\n",
    "            nutritions = dishes[curr_dish]['nutritions']\n",
    "            \n",
    "            for n in range(len(nutritions)):\n",
    "                prto_type = nutritions[n]['name']\n",
    "                if prto_type in unique_nutritions.keys():\n",
    "                    unique_nutritions[prto_type]+=1\n",
    "                else:\n",
    "                    unique_nutritions[prto_type] = 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ჯერ ვნახოთ რამდენი სახის ნუტრიენტები გვაქვს "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unique_nutritions.keys())\n",
    "print(\"Num of nutrient types: \"+str(len(unique_nutritions.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ჩვენი პირველი ვარაუდი იყო რომ მაქსიმუმ 5 მახასიათებელი იქნებოდა , თუმცა როგორც ვხედავთ 17 სხვადასხვა სახის ნუტრიენტი გვაქვს"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedNutritions = sorted(unique_nutritions.items(), key=lambda x : x[1], reverse = True)\n",
    "print(sortedNutritions)\n",
    "sortedDictionary = {}\n",
    "for nut in sortedNutritions:\n",
    "    sortedDictionary[nut[0]] = nut[1]\n",
    "print(sortedDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,8))\n",
    "plt.bar(x = sortedDictionary.keys(), height = unique_nutritions.values())\n",
    "plt.title('Number of occurrences for each Nutrition')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ნუტრიენტებში ლიდერობენ კალორიები , პროტეინები , ნახშირწყლები,ცხიმები , შაქარი , ყველაზე მცირე რაოდენობით არის Vit C, Trn Fat,Ply Fat,Mon Fat,Vit A . \n",
    "ვინაიდან მათი რაოდენობა ძალიან მცირეა , გადავწყვიტეთ საერთოდ გადაგვეყარა.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredNutritions = {}\n",
    "not_needed_prots =['Vit A', 'Vit C', 'Trn Fat', 'Potass.',\n",
    "                    'Mon Fat', 'Ply Fat','Iron','Calcium','Chol','Sat Fat']\n",
    "for nutritionName in sortedDictionary.keys():\n",
    "    if nutritionName not in not_needed_prots:\n",
    "        filteredNutritions[nutritionName] = sortedDictionary[nutritionName]\n",
    "print(filteredNutritions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.pie(filteredNutritions.values(), labels = filteredNutritions.keys(),autopct = \"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "დავთვალოთ საჭმელების უნიკალური მახასიათებლები 2 პარამეტრად, \n",
    "1.მომხმარებელს რამდენი აქვს შეყვანილი(რამდენი ჭამა)\n",
    "2.მიზანი (აპლიკაციამ რამდენი დაუნიშნა)\n",
    "ვნახოთ არის თუ არა დივერგენცია მონაცემებში და ნამდვილად არის თუ არა ტოტალები ტოლი ცალკეული ნუტრიენტიების ჯამების. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "როგორც აღვნიშნეთ 5 ტიპის ნუტრიენტი გადავაგდეთ, რადგან მათი მაჩვენებლი მნიშვნელოვნად მცირე იყო დანარჩენ ნუტრიენტებთან შედარებით . შესაბამისად დათვლებს მხოლოდ prot_names_ში არსებულ ნუტრიენტებზე გავაკეთებთ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_names = ['Calories', 'Carbs', 'Fat', 'Protein', 'Sodium', 'Sugar', 'Fiber']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ამ ეტაპზე ჩვენი მიზანია ვნახოთ რამდენად სწორია მონაცემები . დავთვალოთ თითოეულ სტრიქონში არსებული ნუტრიენტებისთვის ჯამები თუ ემთხვევა ტოტალების სვეტში არსებულ მნიშვნელობებს . ყოველი დაუმთხვეველი ტიპი ჩავყაროთ მასივში და ვნახოთ რა დივერგენცია ხდება ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_calories = []\n",
    "total_carbs = []\n",
    "total_fat = []\n",
    "total_protein = []\n",
    "total_sodium = []\n",
    "total_sugar = []\n",
    "total_fiber = []\n",
    "\n",
    "\n",
    "totals = [total_calories,total_carbs,total_fat,total_protein,\n",
    "          total_sodium, total_sugar,total_fiber,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_totals(tot_data):\n",
    "    result = {}\n",
    "\n",
    "    for curr_tot in tot_data:\n",
    "        prot_name = curr_tot['name']\n",
    "        if prot_name in not_needed_prots:\n",
    "            continue\n",
    "        prot_val = curr_tot['value']\n",
    "        if prot_name not in result.keys():\n",
    "            result[prot_name] = prot_val\n",
    "        else: \n",
    "            result[prot_name] += prot_val\n",
    "        \n",
    "        totals[prot_names.index(prot_name)].append(prot_val)\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ასევე ბარემ ამოვიღოთ გოლები რაც დაუწესა აპლიკაციამ მომხმარებელს "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goal_calories = []\n",
    "goal_carbs = []\n",
    "goal_fat = []\n",
    "goal_protein = []\n",
    "goal_sodium = []\n",
    "goal_sugar = []\n",
    "goal_fiber = []\n",
    "\n",
    "\n",
    "goals = [goal_calories,goal_carbs,goal_fat,goal_protein,\n",
    "         goal_sodium,goal_sugar,goal_fiber]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_goals(goal_data):\n",
    "    for curr_goal in goal_data:\n",
    "        prot_name = curr_goal['name']\n",
    "        if prot_name in not_needed_prots:\n",
    "            continue\n",
    "        prot_value = curr_goal['value']\n",
    "        goals[prot_names.index(prot_name)].append(prot_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ამათი დანიშნულებაც აღვწეროთ რომ გავერკვევით"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divergence = []\n",
    "dishes_count = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replacer(value):\n",
    "    return value.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sums():\n",
    "    result = {}\n",
    "    \n",
    "    dishes = json.loads(data.iloc[i,2])\n",
    "    \n",
    "    for dish in dishes:\n",
    "        dish_per_day = dish['dishes']\n",
    "        dishes_count.append(len(dish_per_day))\n",
    "        \n",
    "        for food in dish_per_day:\n",
    "            nutritions = food['nutritions']\n",
    "            \n",
    "            for prot in nutritions:\n",
    "                prot_name = prot['name']\n",
    "                if prot_name in not_needed_prots:\n",
    "                    continue\n",
    "                prot_val = prot['value']\n",
    "                if prot_name not in result.keys():\n",
    "                    result[prot_name] = int(replacer(prot_val))\n",
    "                else:\n",
    "                    result[prot_name] += int(replacer(prot_val))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkForDivergence(tots, index):\n",
    "    sums = count_sums()\n",
    "    if tots != sums:\n",
    "        divergence.append((index, sums, tots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_check = True\n",
    "gt_check = False\n",
    "for i in range(data.shape[0]):\n",
    "    sums = count_sums()\n",
    "\n",
    "    main_info = json.loads(data.iloc[i,3])\n",
    "\n",
    "    total_data = main_info['total']     \n",
    "    goal_data = main_info['goal']\n",
    "    fill_goals(goal_data)\n",
    "    \n",
    "    checkForDivergence(count_totals(total_data), i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(divergence))\n",
    "for index in range(20):\n",
    "    print(divergence[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "დივერგენციების სტატუსის შემოწმებისას აღმოჩნდა , რომ 918 ჩანაწერში გვხდება აცდენა ტოტალსა და ხელით აჯამულ მონაცემებს შორის . საინტერესო ფაქტია ის , რომ აცდენილი მნიშვნელობების შეფარდება ზუსტად 2_ის ტოლია. ეს ფაქტი სავარაუდოდ აპლიკაციის ბექენდის გამოა, სადაც მონაცემების გადუბლირება ხდება.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ამასთანავე, დატის დათვალიერებისას , თვალში მოგვხვდა ზოგიერთი მონაცემის უარყოფითობა . გადავწყვიტეთ , რომ გამოვიკვლიოთ მსგავის უარყოფითი მნიშვნელობები "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negatives = {}\n",
    "for i in range(data.shape[0]):\n",
    "    dcol = json.loads(data.iloc[i,2])\n",
    "    for dish in dcol:\n",
    "        for food in dish['dishes']:\n",
    "            for nutrients in food['nutritions']:\n",
    "                if int(replacer(nutrients['value'])) <0 :\n",
    "                    if food['name'] not in negatives.keys():\n",
    "                        protValTupla = (nutrients['name'],int(replacer(nutrients['value'])))\n",
    "                        protSet = set(protValTupla)\n",
    "                        negatives[food['name']] = [1,protSet]\n",
    "                    else:\n",
    "                        negatives[food['name']][0] += 1\n",
    "                        protValTupla = (nutrients['name'],int(replacer(nutrients['value'])))\n",
    "                        negatives[food['name']][1].add(protValTupla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedNegatives = sorted(negatives.items(), key=lambda item: -item[1][0])\n",
    "for key,value in sortedNegatives:\n",
    "    print(key,value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedNegatives = sorted(negatives.items(), key=lambda item: -item[1][0])\n",
    "negativesDict = {'Breastfeeding':0,'CUSTOM_ADJUST':0,\n",
    "                 'Other':0}\n",
    "for key,value in sortedNegatives:\n",
    "    if 'Breastfeeding' in key or 'Generic' in key :\n",
    "        negativesDict['Breastfeeding'] +=1\n",
    "    elif 'CUSTOM ADJUST' in key or 'Net Carb Adjustment' in key:\n",
    "        negativesDict['CUSTOM_ADJUST'] +=1    \n",
    "    else:\n",
    "        negativesDict['Other'] +=1\n",
    "print(negativesDict)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "plt.pie(negativesDict.values(), labels = negativesDict.keys(),autopct = \"%1.1f%%\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "უარყოფითი დატის გაანალიზებისას , უპირატესობა დაიკავა BreastFeeding_მა. მიუხედავად ამ ჩარტში 22 პროცენტისა გარკვეული მომხმარებლები , BreastFeeding_ს სხვადსხვა ტიპის ქვეშ აერთიანებენ . Other ნაწილი წვრილ-წვრილი და მრავალი ტიპის საკვებია ,ამიტომაც გამოვიდა ყველაზე ბევრი . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for goal in goals:\n",
    "    print(len(goal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "საბოლოოდ , არსებული მონაცემებიდან გვინდა რომ მივიღოთ, უფრო გამარტივებული და \n",
    "გასუფთავებული მონაცემები.\n",
    "ვაგდებთ  ნუტრიენტებიდან 10 ცალ,ყველაზე ცოტა რაოდენობის, ნუტრიენტს.\n",
    "ახალ ცხრილში გვინდა რომ მონაცემები დავალაგოთ თარიღების ჭრილში.\n",
    "ნუტრიენტების თითოეული მონაცემი  იქნება ტოტალური მაჩვენებელი,საშუალო მაჩვენებელი დღეების ჭრილში. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ავაგოთ ახალი დიქშენერი ინფორმაციის . პირველი 3 სვეტი იქნება თარიღი , აქტივობა და რამდენი საჭმელი შეიჭამა იმ დღეს.\n",
    "შემდეგ იქნება ჯამური და საშუალო რაოდენობები ნუტრიენტების რათა შემდეგ მოხდეს მათი გამოყენება თარიღების კლასტერიზაციისას. თარიღების კლასტერიზაცია იმიტომ ავირჩიეთ, რომ ყველა თარიკი უნიკალურია , და შეიცავს გასაგებ მონაცემებს. // აქ ტექსტი უნდა დავარედაქტიროთ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = {}\n",
    "new_data['Date'] = []\n",
    "new_data['Week_Day'] = []\n",
    "new_data['Month'] = []\n",
    "new_data['User_Activity'] = []\n",
    "new_data['Food_Count'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['total_calories'] = []\n",
    "new_data['total_carbs'] = []\n",
    "new_data['total_fat'] = []\n",
    "new_data['total_protein'] = []\n",
    "new_data['total_sodium']= []\n",
    "new_data['total_sugar'] = []\n",
    "new_data['total_fiber'] = []\n",
    "\n",
    "totals_new_data = [\n",
    "    new_data['total_calories'], new_data['total_carbs'], new_data['total_fat'],\n",
    "    new_data['total_protein'], new_data['total_sodium'], new_data['total_sugar'],\n",
    "    new_data['total_fiber']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range( int((end-start).days)+1):\n",
    "    dat = start+timedelta(i)\n",
    "    new_data['Work Day'].append(dat.strftime('%A'))\n",
    "    new_data['Month'].append(dat.strftime(\"%B\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ნუტრიენტების ჯამური რაოდენობების დასათვლელად მოცემულ დატაში გადავყვებით თითოეული საჭმლის მონაცემებს ყოველი თარიღისთვის და ვჯამავთ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countTotals(tmp_data, tmp):   \n",
    "    for j in range(tmp_data.shape[0]): \n",
    "\n",
    "        dloc = json.loads(tmp_data.iloc[j, 2])\n",
    "        for dish in dloc:\n",
    "            for food in dish['dishes']:\n",
    "                for nutrient in food['nutritions']:\n",
    "                    if nutrient['name'] in prot_names:\n",
    "                        index = prot_names.index(nutrient['name'])\n",
    "                        value = replacer(nutrient['value'])\n",
    "                        tmp[index] += int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['goal_calories'] = []\n",
    "new_data['goal_carbs'] = []\n",
    "new_data['goal_fat'] = []\n",
    "new_data['goal_protein'] = []\n",
    "new_data['goal_sodium']= []\n",
    "new_data['goal_sugar'] = []\n",
    "new_data['goal_fiber'] = []\n",
    "\n",
    "goals_new_data = [\n",
    "    new_data['goal_calories'], new_data['goal_carbs'], new_data['goal_fat'],\n",
    "    new_data['goal_protein'], new_data['goal_sodium'], new_data['goal_sugar'],\n",
    "    new_data['goal_fiber']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countGoals(tmp_data, tmp):   \n",
    "    for j in range(tmp_data.shape[0]): \n",
    "\n",
    "        gloc = json.loads(tmp_data.iloc[j, 3])\n",
    "        for goal in gloc['goal']:\n",
    "            if goal['name'] in prot_names:\n",
    "                name = goal['name']\n",
    "                index = prot_names.index(name)\n",
    "                value = goal['value']\n",
    "                tmp[index] += int(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def countFood(data):\n",
    "    res = 0\n",
    "    \n",
    "    for j in range(data.shape[0]):\n",
    "        food_entries = json.loads(data.iloc[j, 2])\n",
    "        food = food_entries[0]\n",
    "        res += len(food['dishes'])\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "გადავურბინოთ თითოეულ თარიღს მოცემულ ინტერვალში და დავთვალოთ საჭმლის რაოდენობა, ჯამური ნუტრიენტების რაოდენობები. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_interval = int((end-start).days)+1\n",
    "for i in range(time_interval):\n",
    "    date = start+timedelta(i)\n",
    "    date = date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    tmp_data = data[data[data.columns[1]] == date]\n",
    "    food_count = countFood(tmp_data)\n",
    "    \n",
    "    tmp_totals = np.zeros(len(prot_names))\n",
    "    countTotals(tmp_data, tmp_totals)\n",
    "    for k in range(len(prot_names)):\n",
    "        totals_new_data[k].append(tmp_totals[k])\n",
    "        \n",
    "    tmp_goals = np.zeros(len(prot_names))\n",
    "    countGoals(tmp_data, tmp_goals)\n",
    "    for k in range(len(prot_names)):\n",
    "        goals_new_data[k].append(tmp_goals[k])\n",
    "        \n",
    "    new_data['Date'].append(date)\n",
    "    new_data['User_Activity'].append(len(tmp_data[tmp_data.columns[0]].unique()))\n",
    "    new_data['Food_Count'].append(food_count)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame(new_data)\n",
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sesacvlelia\n",
    "\n",
    "საბოლოოდ მივიღეთ ახალი ცხრილი , რომელშიც 500000 სტრიქონის მაგივრად გვაქვს 208 სტრიქონი და 2გბ_ს მაგივრად რამდენიმე კილობაიტი ინფორმაცია . საინტერესო ფაქტი , რომელიც ვერ გავარკვიეთ ჯერ არის , რომ დატაში სრულიად უგულვებელყოფილია სოდიუმის ასპექტი . რატომ არ ვიცით.თუმცა ვიკვლევთ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## მიზანსა და რეალობას შორის სხვაობა"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['diff_calories'] = []\n",
    "new_data['diff_carbs'] = []\n",
    "new_data['diff_fat'] = []\n",
    "new_data['diff_protein'] = []\n",
    "new_data['diff_sodium']= []\n",
    "new_data['diff_sugar'] = []\n",
    "new_data['diff_fiber'] = []\n",
    "\n",
    "for i in frame.iterrows():\n",
    "    for prot in prot_names:\n",
    "        tot = 'total_' + prot.lower()\n",
    "        goal = 'goal_' + prot.lower()\n",
    "        df = 'diff_' + prot.lower()\n",
    "        diff = i[1][tot]-i[1][goal]\n",
    "        new_data[df].append(diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_frame = pd.DataFrame(new_data)\n",
    "tmp_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## შევინახოთ ცალკე ფაილად და განვაგრძოთ და დავტესტოთ რომ ინახება, ვაშა მზადაა კლასტერიზაციისთვის, თუ დაგვჭირდა average-ებს იქაც დავთვლით"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_frame.to_csv('DataForClusterization.csv')\n",
    "testDB = pd.read_csv('DataForClusterization.csv')\n",
    "testDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
